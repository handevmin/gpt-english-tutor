'use client';

import { useState, useEffect, useRef } from 'react';
import { getSpeechRate } from '../data';

// Web Speech API íƒ€ì… ì •ì˜
declare global {
  interface Window {
    SpeechRecognition: typeof SpeechRecognition;
    webkitSpeechRecognition: typeof SpeechRecognition;
    mozSpeechRecognition: typeof SpeechRecognition;
    msSpeechRecognition: typeof SpeechRecognition;
  }
}

interface SpeechHandlerProps {
  isRecording: boolean;
  onRecordingResult: (transcript: string) => void;
  onRecordingEnd: (transcript?: string) => void;
  speechSpeed: number;
  onStartSpeaking: () => void;
  onStopSpeaking: () => void;
  textToSpeak: string | null;
  apiKey: string | null;
  debugMode: boolean;
  currentTranscript: string;
  onStartRecording: () => void;
}

const SpeechHandler: React.FC<SpeechHandlerProps> = ({
  isRecording,
  onRecordingResult,
  onRecordingEnd,
  speechSpeed,
  onStartSpeaking,
  onStopSpeaking,
  textToSpeak,
  apiKey,
  debugMode = false,
  currentTranscript,
  onStartRecording,
}) => {
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [errorMessage, setErrorMessage] = useState<string | null>(null);
  const [hasPermission, setHasPermission] = useState<boolean | null>(null);
  const [isProcessingAudio, setIsProcessingAudio] = useState(false);
  
  // ìŒì„± ì¸ì‹ ê´€ë ¨ ìƒíƒœ
  const [mediaRecorder, setMediaRecorder] = useState<MediaRecorder | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const speechSynthesisRef = useRef<SpeechSynthesisUtterance | null>(null);
  
  // ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œ í™•ì¸ ë° ì´ˆê¸°í™”
  useEffect(() => {
    console.log('ë§ˆì´í¬ ê¶Œí•œ í™•ì¸ ì¤‘...');
    
    const initAudio = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        setHasPermission(true);
        console.log('ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©ë¨');
        
        const recorder = new MediaRecorder(stream);
        
        recorder.onstart = () => {
          console.log('ë…¹ìŒ ì‹œì‘ë¨');
          audioChunksRef.current = [];
          setErrorMessage(null);
        };
        
        recorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            audioChunksRef.current.push(event.data);
          }
        };
        
        recorder.onstop = async () => {
          console.log('ë…¹ìŒ ì¢…ë£Œë¨');
          
          if (audioChunksRef.current.length === 0) {
            console.log('ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°ì´í„° ì—†ìŒ');
            return;
          }
          
          if (!apiKey) {
            setErrorMessage('OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤');
            return;
          }
          
          setIsProcessingAudio(true);
          
          try {
            // ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ë³€í™˜
            const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
            
            // íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í¬ë©´ ê²½ê³ 
            if (audioBlob.size > 25 * 1024 * 1024) { // 25MB ì´ìƒì´ë©´
              setErrorMessage('ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤. ë” ì§§ê²Œ ë…¹ìŒí•´ì£¼ì„¸ìš”.');
              setIsProcessingAudio(false);
              return;
            }
            
            // ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìœ¼ë©´ Whisper APIì—ì„œ ì˜¤ë¥˜ ë°œìƒ ë°©ì§€
            // "Audio file is too short. Minimum audio length is 0.1 seconds." ì˜¤ë¥˜ í•´ê²°
            if (audioBlob.size < 2000) { // ì•½ 0.1ì´ˆ ì´í•˜ë¡œ ì¶”ì •ë˜ëŠ” ì‘ì€ íŒŒì¼
              console.log('ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ (í¬ê¸°: ' + audioBlob.size + ' bytes). ì²˜ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.');
              
              // ì¡ìŒì´ë‚˜ ë§¤ìš° ì§§ì€ ë…¹ìŒìœ¼ë¡œ ê°„ì£¼í•˜ê³  ë¹ˆ í…ìŠ¤íŠ¸ ì„¤ì •
              setTranscript('');
              
              // ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ìƒíƒœ í•´ì œ
              setIsProcessingAudio(false);
              
              // ë¹ˆ í…ìŠ¤íŠ¸ë¡œ ë…¹ìŒ ì¢…ë£Œ ì²˜ë¦¬ (AI ì‘ë‹µ ìœ ë„)
              // ë¹ˆ ë¬¸ìì—´ì„ ì „ë‹¬í•˜ì—¬ ë„ˆë¬´ ì§§ì€ ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬
              onRecordingEnd('');
              return;
            }
            
            const formData = new FormData();
            formData.append('file', audioBlob, 'recording.webm');
            formData.append('model', 'whisper-1');
            formData.append('language', 'en');
            
            // ìµœëŒ€ 3ë²ˆ ì¬ì‹œë„
            let attempts = 0;
            const maxAttempts = 3;
            
            // API ìš”ì²­ ì „ ì˜¤ë¥˜ ì´ˆê¸°í™”
            setErrorMessage(null);
            
            // ë³€ìˆ˜ ì„ ì–¸ ë° ì´ˆê¸°í™” 
            let response = null;
            let result = null;
            
            // API ìš”ì²­ ì‹œë„
            while (attempts < maxAttempts) {
              try {
                console.log(`ìŒì„± ì¸ì‹ API ìš”ì²­ ì‹œë„ ${attempts + 1}/${maxAttempts}...`);
                
                // Whisper API í˜¸ì¶œ
                response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
                  method: 'POST',
                  headers: {
                    'Authorization': `Bearer ${apiKey}`
                  },
                  body: formData
                });
                
                if (!response.ok) {
                  if (response.status === 429) {
                    console.log(`API ìš”ì²­ í•œë„ ì´ˆê³¼ (429): ${attempts + 1}ë²ˆì§¸ ì‹œë„`);
                    
                    // ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì¬ì‹œë„
                    if (attempts < maxAttempts - 1) {
                      const waitTime = 2000 * (attempts + 1); // ëŒ€ê¸° ì‹œê°„ì„ ì ì  ëŠ˜ë¦¼
                      console.log(`${waitTime/1000}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤.`);
                      
                      // ì‚¬ìš©ìì—ê²Œ ëŒ€ê¸° ë©”ì‹œì§€ í‘œì‹œ
                      setErrorMessage(`API ìš”ì²­ í•œë„ ì´ˆê³¼: ${(attempts + 2)}ë²ˆì§¸ ì‹œë„ ì¤€ë¹„ ì¤‘...`);
                      
                      // ëŒ€ê¸° í›„ ì¬ì‹œë„
                      await new Promise(resolve => setTimeout(resolve, waitTime));
                      attempts++;
                      continue;
                    } else {
                      throw new Error('OpenAI API ìš”ì²­ í•œë„ ì´ˆê³¼: ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš” (429)');
                    }
                  } else {
                    // ë‹¤ë¥¸ HTTP ì˜¤ë¥˜
                    const errorText = await response.text().catch(() => 'ì‘ë‹µ ë‚´ìš©ì„ ì½ì„ ìˆ˜ ì—†ìŒ');
                    throw new Error(`API ì˜¤ë¥˜: ${response.status} - ${errorText}`);
                  }
                }
                
                // ì„±ê³µì ì¸ ì‘ë‹µ ì²˜ë¦¬
                try {
                  result = await response.json();
                  console.log('Whisper API ì‘ë‹µ ì„±ê³µ:', result);
                  break; // ì„±ê³µí•˜ë©´ ë°˜ë³µ ì¢…ë£Œ
                } catch (jsonError) {
                  throw new Error(`ì‘ë‹µ ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜: ${jsonError instanceof Error ? jsonError.message : String(jsonError)}`);
                }
              } catch (error) {
                console.error(`ì‹œë„ ${attempts + 1}/${maxAttempts} ì‹¤íŒ¨:`, error);
                
                // ë§ˆì§€ë§‰ ì‹œë„ì˜€ìœ¼ë©´ ì˜¤ë¥˜ ë°œìƒ
                if (attempts >= maxAttempts - 1) {
                  console.error('ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ë„ë‹¬. ìµœì¢… ì˜¤ë¥˜:', error);
                  throw error;
                }
                
                // ëŒ€ê¸° í›„ ì¬ì‹œë„
                const waitTime = 1000 * (attempts + 1);
                await new Promise(resolve => setTimeout(resolve, waitTime));
                attempts++;
              }
            }
            
            if (result && result.text) {
              const recognizedText = result.text.trim();
              setTranscript(recognizedText);
              
              // ì¸ì‹ëœ í…ìŠ¤íŠ¸ë¥¼ ë¶€ëª¨ ì»´í¬ë„ŒíŠ¸ë¡œ ì „ë‹¬
              onRecordingResult(recognizedText);
              
              // ëª…ì‹œì ìœ¼ë¡œ ì§§ì€ ì§€ì—° í›„ì— ë…¹ìŒ ì¢…ë£Œ ì´ë²¤íŠ¸ ë°œìƒì‹œí‚´
              // ì´ë ‡ê²Œ í•˜ë©´ UIì— í…ìŠ¤íŠ¸ê°€ í‘œì‹œëœ í›„ ì±„íŒ… ë©”ì‹œì§€ë¡œ ì¶”ê°€ë¨
              setTimeout(() => {
                console.log('ìŒì„± ì¸ì‹ ì™„ë£Œ, ì±„íŒ…ì— ë©”ì‹œì§€ ì¶”ê°€ ì¤‘...');
                onRecordingEnd();
              }, 300);
            }
          } catch (error) {
            console.error('Whisper API ì˜¤ë¥˜:', error);
            setErrorMessage(`ìŒì„± ì¸ì‹ ì˜¤ë¥˜: ${error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`);
            // ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ë…¹ìŒ ì¢…ë£Œ ì²˜ë¦¬
            onRecordingEnd();
          } finally {
            setIsProcessingAudio(false);
          }
        };
        
        setMediaRecorder(recorder);
        mediaRecorderRef.current = recorder;
        
      } catch (error) {
        console.error('ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜:', error);
        setHasPermission(false);
        setErrorMessage('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤');
      }
    };
    
    initAudio();
    
    return () => {
      // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
      if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
        mediaRecorderRef.current.stop();
      }
    };
  }, [apiKey, onRecordingEnd, onRecordingResult]);
  
  // ë…¹ìŒ ìƒíƒœ ë³€ê²½ ì²˜ë¦¬
  useEffect(() => {
    if (!mediaRecorder || hasPermission === false) {
      return;
    }
    
    try {
      if (isRecording && mediaRecorder.state === 'inactive') {
        console.log('ë…¹ìŒ ì‹œì‘');
        mediaRecorder.start();
      } else if (!isRecording && mediaRecorder.state === 'recording') {
        console.log('ë…¹ìŒ ì¤‘ì§€');
        mediaRecorder.stop();
      }
    } catch (error) {
      console.error('ë…¹ìŒ ìƒíƒœ ë³€ê²½ ì˜¤ë¥˜:', error);
      setErrorMessage(`ë…¹ìŒ ì˜¤ë¥˜: ${error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`);
    }
  }, [isRecording, mediaRecorder, hasPermission]);
  
  // ì´ì „ ìŒì„± í•©ì„± ì·¨ì†Œ
  const cancelPreviousSpeech = () => {
    if (window.speechSynthesis) {
      console.log('ì´ì „ ìŒì„± í•©ì„± ì·¨ì†Œ');
      window.speechSynthesis.cancel();
      
      // ì·¨ì†Œ í›„ ì•½ê°„ì˜ ì§€ì—°ì„ ë‘ì–´ ë¸Œë¼ìš°ì € ìŒì„± ì—”ì§„ì´ ì´ˆê¸°í™”ë˜ë„ë¡ í•©ë‹ˆë‹¤
      return new Promise(resolve => setTimeout(resolve, 150));
    }
    return Promise.resolve();
  };
  
  // ìŒì„± í•©ì„±
  useEffect(() => {
    if (!textToSpeak) return;
    
    console.log('ìŒì„± í•©ì„± ì‹œì‘:', textToSpeak);
    
    let isMounted = true; // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ìƒíƒœ ì¶”ì 
    let timeoutId: NodeJS.Timeout;
    
    // ë¹„ë™ê¸° í•¨ìˆ˜ë¡œ ìŒì„± í•©ì„± í”„ë¡œì„¸ìŠ¤ ì‹œì‘
    const startSpeechProcess = async () => {
      // ì´ì „ ìŒì„± í•©ì„±ì´ ìˆì—ˆë‹¤ë©´ ì·¨ì†Œí•˜ê³  ì ì‹œ ëŒ€ê¸°
      await cancelPreviousSpeech();
      
      if (!isMounted) return; // ì»´í¬ë„ŒíŠ¸ê°€ ì–¸ë§ˆìš´íŠ¸ë˜ì—ˆìœ¼ë©´ ì¤‘ë‹¨
      
      // ìŒì„± í•©ì„± ì‹œì‘ ì „ ì•½ê°„ì˜ ì§€ì—° ì ìš© (ì´ì „ ìŒì„±ê³¼ì˜ ì¶©ëŒ ë°©ì§€)
      timeoutId = setTimeout(() => {
        try {
          // ìŒì„± í•©ì„± ì—”ì§„ì´ ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸
          let voices = window.speechSynthesis.getVoices();
          if (voices.length === 0) {
            console.log('ìŒì„± ëª©ë¡ì„ ì•„ì§ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ, ë¡œë”© ëŒ€ê¸° ì¤‘...');
            
            // ìŒì„± ë¡œë“œë¥¼ ìœ„í•œ ì¬ì‹œë„ ê¸°ëŠ¥ (0.5ì´ˆ í›„ ë‹¤ì‹œ ì‹œë„)
            const retryAfterDelay = () => {
              if (!isMounted) return; // ë§ˆìš´íŠ¸ ìƒíƒœ í™•ì¸
              
              voices = window.speechSynthesis.getVoices();
              if (voices.length > 0) {
                console.log('ìŒì„± ëª©ë¡ ë¡œë“œë¨, ìŒì„± í•©ì„± ì‹œì‘');
                startSpeaking(voices);
              } else {
                console.log('ìŒì„± ëª©ë¡ì„ ì—¬ì „íˆ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ, 0.5ì´ˆ í›„ ë‹¤ì‹œ ì‹œë„');
                setTimeout(retryAfterDelay, 500);
              }
            };
            
            // ì¼ë¶€ ë¸Œë¼ìš°ì €ì—ì„œëŠ” ë¹„ë™ê¸°ì ìœ¼ë¡œ ë¡œë“œë¨
            const voicesChangedHandler = () => {
              if (!isMounted) return; // ë§ˆìš´íŠ¸ ìƒíƒœ í™•ì¸
              
              voices = window.speechSynthesis.getVoices();
              if (voices.length > 0) {
                // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€)
                window.speechSynthesis.onvoiceschanged = null;
                startSpeaking(voices);
              }
            };
            
            window.speechSynthesis.onvoiceschanged = voicesChangedHandler;
            
            // ì²« ë²ˆì§¸ ì¬ì‹œë„ ì˜ˆì•½
            setTimeout(retryAfterDelay, 500);
            return;
          }
          
          startSpeaking(voices);
          
        } catch (error) {
          console.error('ìŒì„± í•©ì„± ì´ˆê¸°í™” ì˜¤ë¥˜:', error);
          if (isMounted) {
            setIsSpeaking(false);
            onStopSpeaking();
          }
        }
      }, 300); // ì§€ì—° ì‹œê°„
    };
    
    // ìŒì„± í•©ì„± í”„ë¡œì„¸ìŠ¤ ì‹œì‘
    startSpeechProcess();
    
    // ë‚´ë¶€ í•¨ìˆ˜ë¡œ ì‹¤ì œ ìŒì„± í•©ì„± ì‹œì‘ ë¡œì§ ë¶„ë¦¬
    function startSpeaking(voices: SpeechSynthesisVoice[]) {
      if (!isMounted) return; // ë§ˆìš´íŠ¸ ìƒíƒœ í™•ì¸
      
      try {
        // textToSpeakê°€ nullì´ë©´ ë°”ë¡œ ë¦¬í„´
        if (textToSpeak === null) return;
        
        const speech = new SpeechSynthesisUtterance(textToSpeak);
        speechSynthesisRef.current = speech;
        
        speech.lang = 'en-US';
        speech.rate = getSpeechRate(speechSpeed);
        
        // ìì—°ìŠ¤ëŸ¬ìš´ ëª©ì†Œë¦¬ë¥¼ ìœ„í•œ ì¶”ê°€ ì„¤ì •
        speech.pitch = 1.0; // ê¸°ë³¸ê°’ì€ 1.0, ë²”ìœ„ëŠ” 0~2
        speech.volume = 1.0; // ìµœëŒ€ ë³¼ë¥¨
        
        // ë¬¸ì¥ ì•ë’¤ì— ì•½ê°„ì˜ ê³µë°±ì„ ì¶”ê°€í•˜ì—¬ ë” ìì—°ìŠ¤ëŸ¬ìš´ ë°œí™” êµ¬í˜„
        const pauseCharacter = ','; // ë¯¸ì„¸í•œ íœ´ì§€ë¥¼ ìœ„í•œ ë¬¸ì ì¶”ê°€
        if (!textToSpeak.startsWith(pauseCharacter)) {
          speech.text = pauseCharacter + ' ' + textToSpeak;
        }
        
        // ë¸Œë¼ìš°ì €ë³„ ê³ í’ˆì§ˆ ìŒì„± ì„ íƒ ë¡œì§ ê°œì„ 
        console.log('ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„±:', voices.length);
        
        if (debugMode) {
          console.log('ì‚¬ìš© ê°€ëŠ¥í•œ ìŒì„± ëª©ë¡:', voices.map(v => `${v.name} (${v.lang})`));
        }
        
        // ìµœì‹  ê³ í’ˆì§ˆ ìŒì„± ëª©ë¡ (ë¸Œë¼ìš°ì €ë³„ ìš°ì„  ìˆœìœ„)
        const preferredVoices = [
          // Chrome/Edge ê³ í’ˆì§ˆ ìŒì„±
          'Microsoft Aria Online (Natural) - English (United States)',
          'Google UK English Female',
          'Microsoft Libby Online (Natural)',
          'Microsoft Jenny Online (Natural)',
          // Safari ê³ í’ˆì§ˆ ìŒì„±
          'Samantha',
          'Ava',
          // Firefox ìŒì„±
          'Karen',
          'Allison'
        ];
        
        // 1. ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± ê²€ìƒ‰
        let selectedVoice = null;
        for (const voiceName of preferredVoices) {
          const foundVoice = voices.find(v => v.name === voiceName && v.lang.includes('en'));
          if (foundVoice) {
            selectedVoice = foundVoice;
            console.log(`ê³ í’ˆì§ˆ ìŒì„± ì„ íƒë¨: ${foundVoice.name}`);
            break;
          }
        }
        
        // 2. ìš°ì„ ìˆœìœ„ ìŒì„±ì´ ì—†ìœ¼ë©´ 'natural' í‚¤ì›Œë“œê°€ ìˆëŠ” ìŒì„± ê²€ìƒ‰
        if (!selectedVoice) {
          const naturalVoice = voices.find(v => 
            v.name.toLowerCase().includes('natural') && 
            v.lang.includes('en-US')
          );
          
          if (naturalVoice) {
            selectedVoice = naturalVoice;
            console.log(`ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± ì„ íƒë¨: ${naturalVoice.name}`);
          }
        }
        
        // 3. ì—¬ì „íˆ ìŒì„±ì´ ì—†ìœ¼ë©´ ì—¬ì„± ìŒì„± ê²€ìƒ‰
        if (!selectedVoice) {
          const femaleVoice = voices.find(voice => 
            voice.lang.includes('en-US') && 
            (voice.name.includes('Female') || voice.name.includes('Samantha') || voice.name.includes('Ava'))
          );
          
          if (femaleVoice) {
            selectedVoice = femaleVoice;
            console.log(`ì—¬ì„± ìŒì„± ì„ íƒë¨: ${femaleVoice.name}`);
          }
        }
        
        // 4. ë§ˆì§€ë§‰ìœ¼ë¡œ ì˜ì–´ ìŒì„± ì¤‘ ì²« ë²ˆì§¸ ì„ íƒ
        if (!selectedVoice) {
          const englishVoice = voices.find(voice => voice.lang.includes('en'));
          if (englishVoice) {
            selectedVoice = englishVoice;
            console.log(`ê¸°ë³¸ ì˜ì–´ ìŒì„± ì„ íƒë¨: ${englishVoice.name}`);
          }
        }
        
        // ì„ íƒëœ ìŒì„± ì ìš©
        if (selectedVoice) {
          speech.voice = selectedVoice;
        }
        
        // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
        speech.onstart = () => {
          if (!isMounted) return; // ë§ˆìš´íŠ¸ ìƒíƒœ í™•ì¸
          console.log('ìŒì„± ì¬ìƒ ì‹œì‘');
          setIsSpeaking(true);
          onStartSpeaking();
        };
        
        speech.onend = () => {
          if (!isMounted) return; // ë§ˆìš´íŠ¸ ìƒíƒœ í™•ì¸
          console.log('ìŒì„± ì¬ìƒ ì¢…ë£Œ');
          setIsSpeaking(false);
          onStopSpeaking();
        };
        
        speech.onerror = (event) => {
          if (!isMounted) return; // ë§ˆìš´íŠ¸ ìƒíƒœ í™•ì¸
          
          // interrupted ì˜¤ë¥˜ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ìƒˆ ìŒì„±ì´ ì‹œì‘ë  ë•Œ ë°œìƒí•˜ë¯€ë¡œ ë¬´ì‹œ
          if (event.error === 'interrupted') {
            console.log('ìŒì„± í•©ì„± interrupted ì˜¤ë¥˜ ë¬´ì‹œë¨ - ì •ìƒì ì¸ ìŒì„± ì „í™˜');
            // interrupted ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ onendê°€ ë°œìƒí•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ
            // ì´ì „ ìŒì„± ìƒíƒœë¥¼ ì´ˆê¸°í™”
            setIsSpeaking(false);
            onStopSpeaking();
            // ì•½ê°„ì˜ ì§€ì—° í›„ ìƒˆ ìŒì„± ì¬ìƒ ì‹œë„ (í•„ìš”í•œ ê²½ìš°)
            if (textToSpeak && isMounted) {
              setTimeout(() => {
                if (isMounted && textToSpeak) {
                  // ìŒì„± ì¬ìƒ ë‹¤ì‹œ ì‹œë„
                  const newSpeech = new SpeechSynthesisUtterance(textToSpeak);
                  if (selectedVoice) newSpeech.voice = selectedVoice;
                  newSpeech.lang = 'en-US';
                  newSpeech.rate = getSpeechRate(speechSpeed);
                  newSpeech.onstart = speech.onstart;
                  newSpeech.onend = speech.onend;
                  newSpeech.onerror = speech.onerror;
                  window.speechSynthesis.speak(newSpeech);
                }
              }, 300);
            }
          } else {
            console.error('ìŒì„± í•©ì„± ì˜¤ë¥˜:', event);
            setIsSpeaking(false);
            onStopSpeaking();
          }
        };
        
        // Chromeê³¼ Edgeì—ì„œ ê¸´ í…ìŠ¤íŠ¸ê°€ ì¤‘ê°„ì— ëŠê¸°ëŠ” ë¬¸ì œ í•´ê²° (15ì´ˆ ì´ìƒ ë¬¸ì œ)
        // SpeechSynthesis ë¬¸ì œ í•´ê²°ì±…: https://stackoverflow.com/questions/21947730/chrome-speech-synthesis-with-longer-texts
        const maxSpeechLength = 200; // ìµœëŒ€ ë¬¸ì ìˆ˜ ì œí•œ
        
        // ê¸´ í…ìŠ¤íŠ¸ì˜ ê²½ìš° ë¶„í• í•˜ì—¬ ì¬ìƒ
        if (speech.text && speech.text.length > maxSpeechLength) {
          console.log('ê¸´ í…ìŠ¤íŠ¸ ê°ì§€: ë¶„í• í•˜ì—¬ ì¬ìƒ');
          
          // í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
          const sentences = speech.text.match(/[^.!?]+[.!?]+/g) || [speech.text];
          
          // ê° ë¬¸ì¥ì„ ê°œë³„ ë°œí™”ë¡œ ì²˜ë¦¬
          let currentIndex = 0;
          
          const speakNextSentence = () => {
            if (!isMounted) return; // ë§ˆìš´íŠ¸ ìƒíƒœ í™•ì¸
            
            if (currentIndex < sentences.length) {
              const sentenceText = sentences[currentIndex];
              currentIndex++;
              
              const sentenceSpeech = new SpeechSynthesisUtterance(sentenceText);
              sentenceSpeech.voice = speech.voice;
              sentenceSpeech.lang = speech.lang;
              sentenceSpeech.rate = speech.rate;
              sentenceSpeech.pitch = speech.pitch;
              
              // ë§ˆì§€ë§‰ ë¬¸ì¥ì´ ì•„ë‹Œ ê²½ìš°
              if (currentIndex < sentences.length) {
                sentenceSpeech.onend = speakNextSentence;
              } else {
                // ë§ˆì§€ë§‰ ë¬¸ì¥ì˜ ê²½ìš° ì›ë˜ onend ì´ë²¤íŠ¸ ì²˜ë¦¬ê¸° ì‚¬ìš©
                sentenceSpeech.onend = speech.onend;
              }
              
              // ì²« ë²ˆì§¸ ë¬¸ì¥ë§Œ onstart ì´ë²¤íŠ¸ ë°œìƒ
              if (currentIndex === 1) {
                sentenceSpeech.onstart = speech.onstart;
              }
              
              sentenceSpeech.onerror = speech.onerror;
              
              // ë¬¸ì¥ ì¬ìƒ
              window.speechSynthesis.speak(sentenceSpeech);
            }
          };
          
          // ì²« ë²ˆì§¸ ë¬¸ì¥ë¶€í„° ì‹œì‘
          speakNextSentence();
        } else {
          // ì¼ë°˜ í…ìŠ¤íŠ¸ì˜ ê²½ìš° ë°”ë¡œ ì¬ìƒ
          // ìŒì„± í•©ì„± ì‹œì‘ ì „ ì•½ê°„ì˜ ì¶”ê°€ ì§€ì—° ì ìš© (ìì—°ìŠ¤ëŸ¬ìš´ ì‹œì‘ì„ ìœ„í•´)
          setTimeout(() => {
            if (!isMounted) return; // ë§ˆìš´íŠ¸ ìƒíƒœ í™•ì¸
            window.speechSynthesis.speak(speech);
          }, 200);
        }
      } catch (error) {
        console.error('ìŒì„± í•©ì„± ìµœì¢… ì˜¤ë¥˜:', error);
        if (isMounted) {
          setIsSpeaking(false);
          onStopSpeaking();
        }
      }
    }
    
    return () => {
      // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ë˜ëŠ” textToSpeak ë³€ê²½ ì‹œ ì •ë¦¬
      isMounted = false; // ë§ˆìš´íŠ¸ ìƒíƒœ í‘œì‹œ ì—…ë°ì´íŠ¸
      clearTimeout(timeoutId);
      
      // ìŒì„± í•©ì„± ì·¨ì†Œ
      if (window.speechSynthesis) {
        window.speechSynthesis.cancel();
      }
    };
    
  }, [textToSpeak, speechSpeed, debugMode, onStartSpeaking, onStopSpeaking]);
  
  // ë””ë²„ê·¸ ì •ë³´ ë Œë”ë§
  const renderDebugInfo = () => {
    if (!debugMode) return null;
    
    return (
      <div className="fixed bottom-0 left-0 right-0 bg-gray-800 text-white p-3 text-xs overflow-auto max-h-36">
        <h3 className="font-bold mb-1">ë””ë²„ê·¸ ì •ë³´</h3>
        <div>
          <p>ë§ˆì´í¬ ê¶Œí•œ: {hasPermission === null ? 'í™•ì¸ ì¤‘...' : hasPermission ? 'í—ˆìš©ë¨' : 'ê±°ë¶€ë¨'}</p>
          <p>ë…¹ìŒ ìƒíƒœ: {isRecording ? 'ë…¹ìŒ ì¤‘' : 'ëŒ€ê¸° ì¤‘'}</p>
          <p>ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘: {isProcessingAudio ? 'Yes' : 'No'}</p>
          <p>ìŒì„± í•©ì„± ìƒíƒœ: {isSpeaking ? 'ìŒì„± ì¶œë ¥ ì¤‘' : 'ëŒ€ê¸° ì¤‘'}</p>
          <p>ì¸ì‹ëœ í…ìŠ¤íŠ¸: {transcript || 'ì—†ìŒ'}</p>
          {errorMessage && (
            <div className="mt-2 p-2 bg-red-800 rounded">
              <p className="text-red-200 font-bold">ì˜¤ë¥˜:</p>
              <p className="text-red-100">{errorMessage}</p>
              {errorMessage.includes('API ìš”ì²­ í•œë„') && (
                <p className="text-yellow-200 mt-1 text-xs">
                  ğŸ’¡ íŒ: OpenAI ë¬´ë£Œ API í‚¤ëŠ” ë¶„ë‹¹ ìš”ì²­ ìˆ˜ ì œí•œì´ ìˆìŠµë‹ˆë‹¤. 1-2ë¶„ ì •ë„ ê¸°ë‹¤ë ¸ë‹¤ê°€ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.
                </p>
              )}
            </div>
          )}
        </div>
      </div>
    );
  };
  
  return (
    <>
      {/* ìŒì„± ì¸ì‹ ê´€ë ¨ UIëŠ” ì—¬ê¸°ì— ì¶”ê°€ */}
      {renderDebugInfo()}
    </>
  );
};

export default SpeechHandler;